---
title: "Reproducibility"
subtitle: 'A *very* brief overview'
author: '<a href="https://gmbernardoharrington.netlify.app/" style="color: #fa2d6e">Gabriel Mateus Bernardo Harrington</a>'
date: '2024-03-14'
date-modified: '`r Sys.Date()`'
date-format: iso
institute: 'Research Associate | Webber Group'
format: 
  ukdri-revealjs:
    smaller: true
    multiplex: true
    footer: |
        Made with the [UKDRI Quarto template](https://github.com/H-Mateus/quarto-ukdri-theme) by [GMBH](https://gmbernardoharrington.netlify.app/).
        Code available on GitHub [here](https://github.com/H-Mateus/presentations_dri-ecr-vascular_reproducibility_2024-03-14).
        Licensed under [CC-BY-SA](http://creativecommons.org/licenses/by-sa/4.0/)
embed-resources: true
bibliography: references.bib
csl: /Users/mateusbernardo-harrington/Documents/citation_styles/nature.csl
---

```{r}
#| label: setup
#| include: false
library(librarian)
pkg <- c("tidyverse", "gt", "leaflet", "DT")
shelf(pkg)
rm(pkg)
```

```{r}
#| label: dri-hexcolours
#| include: false
dri_hexcolours <- c("dark_blue" = "#00326e", "light_grey" = "#c4d1d9",
                    "dark_grey" = "#415767", "sky_blue" = "#0ac8ff",
                    "petrol_blue" = "007faf", "brigth_blue" = "4682ff",
                    "cobalt" = "325ad7", "violet" = "#461e8c", "fuchsia" = "#fa2d6e",
                    "ruby" = "#aa0050", "yellow" = "#ffed00")
```

## Follow the slides online

```{r}
#| include: false
code <- qrcode::qr_code("https://h-mateus.github.io/presentations_dri-ecr-vascular_reproducibility_2024-03-14/2024-02-26_ecr-vascular-meeting_reproducibility.html")
qrcode::generate_svg(code, filename = here::here("images/qrcode.svg"))
```

-   Slides are here: <https://h-mateus.github.io/presentations_dri-ecr-vascular_reproducibility_2024-03-14/2024-02-26_ecr-vascular-meeting_reproducibility.html>

![](images/qrcode.svg)

## Academic journals suck

. . .

::: {layout-ncol="2"}
-   Journal status and paper quality are poorly correlated[@szucs_empirical_2017; @brembs_prestigious_2018]
-   Space is dominated by 5 big publication houses - [they are evil](https://www.youtube.com/watch?v=TzLgGSNq0Wk)[@racimo_ethical_2022]
-   Strong bias against negative results
-   Do they spend their staggering profits checking for obvious signs of fraud, encourage replication or even just make science more readable and accessible? Of course not.[@buranyi_is_2017]
-   Nice documentary on the business of scholarship [here](https://vimeo.com/273358286)[@noauthor_paywall_2018]

[![](images/stop_elseiver.png)](https://stopelsevier.wordpress.com/)
:::

::: notes
-   High IF journals are super competitive \> they get swamped with too-good-to-be-true data by desperate scientists
-   Obscene profit margins \< 35% VS 2/11/21% for Amazon/Google/Apple
:::

## GUIs suck

::: {layout-ncol="2"}
-   Graphical user interface (GUI) tools like Excel, SPSS & Graphpad are very opaque and error prone, as our government learnt during COVID[@hern_covid_2020]
-   The Excel mistake heard around the world and the lasting economic repercussions[@ryssdal_excel_2013]
-   Propriety software - many people can't access it and therefore can't replicate analysis
-   No obvious history of changes made or operations performed

![](images/excel_goof.gif)
:::

## Stats suck

-   Frequentist statistics is used almost exclusively for all science
    -   It is extremely unintuitive and prone to abuse and is rarely done correctly in practise (p-hacking)[@head_extent_2015]
    -   Great video on why p-values are hella variable[@geoff_cumming_intro_2013]
-   Bayesian statistics is a fundamentally different approach, no ground truth assumptions so no pvalues and no p-hacking

::: notes
-   Link to GUI issue - just click buttons on all test to get sig p-value
:::

### Experimental designs suck

::: columns
::: {.column width="40%"}
-   Positive control? pretty pls?
:::

::: {.column width="60%"}
![](images/positivity.gif){fig-align="center" width="40%"}
:::
:::

## Most published research is false

::: incremental
::: columns
::: {.column width="40%"}
-   Whenever people look at this, things don't look great...[@baker_1500_2016; @ioannidis_why_2005; @smaldino_natural_2016; @head_extent_2015]
-   Citations aren't a good metric of quality either[@yang_estimating_2020]
-   Small sample sizes are a big issue, especially in neuroscience[@button_power_2013]
-   That time a major paper that supposedly discovered A$\beta$\*56 a oligermer species, turned out to be full of image manipulations, whoops[@piller_potential_2022]
:::

::: {.column width="60%"}
::: r-stack
[![](images/yang_2020_citation_rates.jpeg){.fragment}](https://www.pnas.org/content/early/2020/04/28/1909046117)

![](images/fraud.gif){.fragment}
:::
:::
:::
:::

::: notes
-   Small sample size = low power = less change to detect non-null effects, but *also* more likely that any significant effect found is false
:::

## An investigator cannot guarantee that the claims made in a study are correct

-   Reproducibility is important not because it ensures that the results are correct, but rather because it ensures transparency and gives us confidence in understanding exactly what was done.

![](images/power_pose.gif){fig-align="center"}

## Solutions

![](images/we_can_do_better.gif)

## Registered reports

-   Largely solves two of the biggest issues - post-hoc hypothesising/data massaging and inability to publish negative results
-   Make it [diamond open access](https://www.coalition-s.org/diamond-open-access/) and you can stick it to the evil publishers too!
    -   Check out PCI: [https://rr.peercommunityin.org/](https://rr.peercommunityin.org/)

::: columns
::: {.column width="50%"}
-   "But the big IF journals don't do registered reports"
-   Yeah, they're evil remember? Of course they won't do anything to make science not suck
    -   Also, Nature does do them now (they're still evil though)
:::

::: {.column width="50%"}
![](images/Screenshot%202024-03-07%20at%2017.21.07.png){width="50%"}
:::
:::

## An idealised workflow - part 1

::: columns
::: {.column width="60%"}
1.  Come up with neat project idea - create repository on DRI GitHub (can be private)
    -   Use this to organise the project (add collaborators, make Gantt charts, etc.)
2.  pre-register study (can be embargoed) and write up registered report
    -   Can do this on [OSF](https://osf.io/)
3.  publish registered report \> get valuable feedback from wise and courteous reviewers (let me dream pls)
    -   In a diamond open access journal ideally!
:::

::: {.column width="40%"}
![](images/imagination.gif)
:::
:::

::: aside
-   Use a [template](https://gin-tonic.netlify.app/standard/) for the GitHub project - be consistent!
:::

## An idealised workflow - part 2

::: columns
::: {.column width="65%"}
4.  Apply for funding if you don't already have it
    -   Some funders are finally pulling their heads out and formally incorporating this into applications
5.  Do study as you said you would (and do any additional work/exploratory stuff as it comes up!)
6.  Publish all the things!
    -   Paper, data, code, container of computational environment (Can use [Zendo](https://zenodo.org/) to generate DOIs for non-paper bits!)
:::

::: {.column width="35%"}
![](images/imagination.gif)
:::
:::

## Let there be code

::: columns
::: {.column width="65%"}
-   Code is just a set of instructions to tell a computer to do something
-   It's an explicit bridge between your raw experimental data (which should be *sacrosanct*!) and your reported stats/figures
-   Great video guide here[@mine_cetinkaya-rundel_improve_2020]
-   Version control: wouldn't it be nice to have a detailed record of all the changes made to all the files in a project when and by whom? Use [Git](https://git-scm.com/) and the [DRI GitHub](https://github.com/UKDRI)!
-   Use whatever, as long as it's open-source
-   Containerisation: encapsulate your computational environment[@nust_ten_2020]
:::

::: {.column width="35%"}
![](images/learn_code.gif)
:::
:::

## Particualr tool suggestions/learning resources

::: columns
::: {.column width="60%"}
-   R or Python for data analysis and use literate programming methods like [Quarto](https://quarto.org/) and/or [Jupyter notebooks](https://jupyter.org/)
-   If you want to do Bayesian but still want a GUI: [JASP](https://jasp-stats.org/)
-   Great guide on using Git with R: <https://happygitwithr.com/>[@hester_lets_nodate]
-   A video guide to Bayes in R [here](https://www.youtube.com/watch?v=EBGKzDAAWYo)[@r-_ladies_amsterdam_r-ladies_2021]
:::

::: {.column width="40%"}
![](images/tools.gif){fig-align="center"}
:::
:::

::: aside
Don't stress over R vs Python, it doesn't matter. 
Quarto is my fav for writing/analysis.
:::

## Data sharing policy {background-image="images/data_sharing.png" background-size="contain"}

<!-- define the final slide  -->

## Thanks for listening {.final-slide background-image="_extensions/H-Mateus/ukdri/title_background.png" style="color: #0ac8ff;"}

::: columns
::: {.column width="70%"}
-   Please don't let the perfect be the enemy of the good!
-   Anything you can do to get closer to more transparent and reproducible research is a huge win as far as I'm concerned
-   Here's a link to the slides again: <https://h-mateus.github.io/presentations_dri-ecr-vascular_reproducibility_2024-03-14/2024-02-26_ecr-vascular-meeting_reproducibility.html>
:::

::: {.column width="30%"}
![](images/qrcode.svg)

[![](https://zenodo.org/badge/770919433.svg)](https://zenodo.org/doi/10.5281/zenodo.10809738)
:::
:::

<!--Use the following to add further logos to the title/final slide-->

<!--Adjust sizing in the CSS file-->

<!-- ::: title-logo-1 -->

<!-- ::: -->

<!-- ::: title-logo-2 -->

<!-- ::: -->

## References
